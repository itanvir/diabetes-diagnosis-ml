{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0996872c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d659a6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing rows and columns:  (97865, 35)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tanvirislam/opt/miniconda3/envs/project/lib/python3.10/site-packages/pandas/core/algorithms.py:798: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  uniques = Index(uniques)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'time_in_hospital', 'medical_specialty', 'num_lab_procedures',\n",
      "       'num_procedures', 'num_medications', 'number_outpatient',\n",
      "       'number_emergency', 'number_inpatient', 'number_diagnoses', 'metformin',\n",
      "       'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride',\n",
      "       'glipizide', 'glyburide', 'pioglitazone', 'rosiglitazone', 'acarbose',\n",
      "       'insulin', 'glyburide-metformin', 'change', 'diabetesMed', 'readmitted',\n",
      "       'num_med_change', 'num_medications|time_in_hospital',\n",
      "       'num_medications|num_procedures', 'time_in_hospital|num_lab_procedures',\n",
      "       'num_medications|num_lab_procedures',\n",
      "       'num_medications|number_diagnoses', 'age|number_diagnoses',\n",
      "       'change|num_medications', 'number_diagnoses|time_in_hospital',\n",
      "       'num_medications|num_med_change', 'gender_1', 'admission_type_id_3',\n",
      "       'admission_type_id_4', 'admission_type_id_5',\n",
      "       'discharge_disposition_id_2', 'discharge_disposition_id_7',\n",
      "       'discharge_disposition_id_10', 'discharge_disposition_id_18',\n",
      "       'discharge_disposition_id_19', 'discharge_disposition_id_20',\n",
      "       'discharge_disposition_id_27', 'discharge_disposition_id_28',\n",
      "       'admission_source_id_4', 'admission_source_id_7',\n",
      "       'admission_source_id_8', 'admission_source_id_9',\n",
      "       'admission_source_id_11', 'max_glu_serum_0', 'max_glu_serum_1',\n",
      "       'A1Cresult_0', 'A1Cresult_1', 'diag_1.0', 'diag_2.0', 'diag_3.0',\n",
      "       'diag_4.0', 'diag_5.0', 'diag_6.0', 'diag_7.0', 'diag_8.0',\n",
      "       'AfricanAmerican', 'Asian', 'Caucasian', 'Hispanic', 'Other'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Generate train/test data\n",
    "X_train, X_test, y_train, y_test = generate_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f43acc1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 7, 8, 32)          320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 4, 4, 32)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 4, 4, 64)          18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 2, 2, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 60,098\n",
      "Trainable params: 60,098\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-21 13:06:54.039258: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/100\n",
      "1324/1328 [============================>.] - ETA: 0s - loss: 0.8265 - accuracy: 0.5298\n",
      "Epoch 1: val_loss improved from inf to 0.69062, saving model to models/model.hdf5\n",
      "1328/1328 [==============================] - 10s 7ms/step - loss: 0.8261 - accuracy: 0.5297 - val_loss: 0.6906 - val_accuracy: 0.5310\n",
      "Epoch 2/100\n",
      "1327/1328 [============================>.] - ETA: 0s - loss: 0.6908 - accuracy: 0.5426\n",
      "Epoch 2: val_loss improved from 0.69062 to 0.68482, saving model to models/model.hdf5\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.6908 - accuracy: 0.5426 - val_loss: 0.6848 - val_accuracy: 0.5485\n",
      "Epoch 3/100\n",
      "1321/1328 [============================>.] - ETA: 0s - loss: 0.6820 - accuracy: 0.5655\n",
      "Epoch 3: val_loss improved from 0.68482 to 0.67017, saving model to models/model.hdf5\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.6817 - accuracy: 0.5659 - val_loss: 0.6702 - val_accuracy: 0.6194\n",
      "Epoch 4/100\n",
      "1322/1328 [============================>.] - ETA: 0s - loss: 0.5456 - accuracy: 0.7154\n",
      "Epoch 4: val_loss improved from 0.67017 to 0.46970, saving model to models/model.hdf5\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.5450 - accuracy: 0.7158 - val_loss: 0.4697 - val_accuracy: 0.7729\n",
      "Epoch 5/100\n",
      "1324/1328 [============================>.] - ETA: 0s - loss: 0.4149 - accuracy: 0.8083\n",
      "Epoch 5: val_loss improved from 0.46970 to 0.41828, saving model to models/model.hdf5\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.4148 - accuracy: 0.8084 - val_loss: 0.4183 - val_accuracy: 0.8092\n",
      "Epoch 6/100\n",
      "1328/1328 [==============================] - ETA: 0s - loss: 0.3823 - accuracy: 0.8295\n",
      "Epoch 6: val_loss improved from 0.41828 to 0.36725, saving model to models/model.hdf5\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.3823 - accuracy: 0.8295 - val_loss: 0.3673 - val_accuracy: 0.8435\n",
      "Epoch 7/100\n",
      "1327/1328 [============================>.] - ETA: 0s - loss: 0.3650 - accuracy: 0.8399\n",
      "Epoch 7: val_loss improved from 0.36725 to 0.36081, saving model to models/model.hdf5\n",
      "1328/1328 [==============================] - 8s 6ms/step - loss: 0.3650 - accuracy: 0.8400 - val_loss: 0.3608 - val_accuracy: 0.8434\n",
      "Epoch 8/100\n",
      "1326/1328 [============================>.] - ETA: 0s - loss: 0.3531 - accuracy: 0.8457\n",
      "Epoch 8: val_loss improved from 0.36081 to 0.35471, saving model to models/model.hdf5\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.3531 - accuracy: 0.8458 - val_loss: 0.3547 - val_accuracy: 0.8464\n",
      "Epoch 9/100\n",
      "1327/1328 [============================>.] - ETA: 0s - loss: 0.3476 - accuracy: 0.8488\n",
      "Epoch 9: val_loss improved from 0.35471 to 0.33400, saving model to models/model.hdf5\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.3475 - accuracy: 0.8488 - val_loss: 0.3340 - val_accuracy: 0.8599\n",
      "Epoch 10/100\n",
      "1323/1328 [============================>.] - ETA: 0s - loss: 0.3413 - accuracy: 0.8538\n",
      "Epoch 10: val_loss improved from 0.33400 to 0.32601, saving model to models/model.hdf5\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.3412 - accuracy: 0.8539 - val_loss: 0.3260 - val_accuracy: 0.8650\n",
      "Epoch 11/100\n",
      "1322/1328 [============================>.] - ETA: 0s - loss: 0.3331 - accuracy: 0.8596\n",
      "Epoch 11: val_loss did not improve from 0.32601\n",
      "1328/1328 [==============================] - 9s 6ms/step - loss: 0.3332 - accuracy: 0.8595 - val_loss: 0.3385 - val_accuracy: 0.8582\n",
      "Epoch 12/100\n",
      "1321/1328 [============================>.] - ETA: 0s - loss: 0.3279 - accuracy: 0.8616\n",
      "Epoch 12: val_loss did not improve from 0.32601\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.3277 - accuracy: 0.8616 - val_loss: 0.3550 - val_accuracy: 0.8445\n",
      "Epoch 13/100\n",
      "1320/1328 [============================>.] - ETA: 0s - loss: 0.3237 - accuracy: 0.8642\n",
      "Epoch 13: val_loss did not improve from 0.32601\n",
      "1328/1328 [==============================] - 8s 6ms/step - loss: 0.3237 - accuracy: 0.8642 - val_loss: 0.3463 - val_accuracy: 0.8507\n",
      "Epoch 14/100\n",
      "1319/1328 [============================>.] - ETA: 0s - loss: 0.3213 - accuracy: 0.8666\n",
      "Epoch 14: val_loss improved from 0.32601 to 0.30801, saving model to models/model.hdf5\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.3212 - accuracy: 0.8666 - val_loss: 0.3080 - val_accuracy: 0.8768\n",
      "Epoch 15/100\n",
      "1323/1328 [============================>.] - ETA: 0s - loss: 0.3168 - accuracy: 0.8680\n",
      "Epoch 15: val_loss did not improve from 0.30801\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.3167 - accuracy: 0.8680 - val_loss: 0.3419 - val_accuracy: 0.8500\n",
      "Epoch 16/100\n",
      "1321/1328 [============================>.] - ETA: 0s - loss: 0.3138 - accuracy: 0.8700\n",
      "Epoch 16: val_loss did not improve from 0.30801\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.3138 - accuracy: 0.8700 - val_loss: 0.3176 - val_accuracy: 0.8672\n",
      "Epoch 17/100\n",
      "1320/1328 [============================>.] - ETA: 0s - loss: 0.3092 - accuracy: 0.8713\n",
      "Epoch 17: val_loss did not improve from 0.30801\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.3094 - accuracy: 0.8713 - val_loss: 0.3309 - val_accuracy: 0.8609\n",
      "Epoch 18/100\n",
      "1325/1328 [============================>.] - ETA: 0s - loss: 0.3075 - accuracy: 0.8728\n",
      "Epoch 18: val_loss did not improve from 0.30801\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.3075 - accuracy: 0.8729 - val_loss: 0.3093 - val_accuracy: 0.8747\n",
      "Epoch 19/100\n",
      "1325/1328 [============================>.] - ETA: 0s - loss: 0.3063 - accuracy: 0.8740\n",
      "Epoch 19: val_loss improved from 0.30801 to 0.30662, saving model to models/model.hdf5\n",
      "1328/1328 [==============================] - 9s 6ms/step - loss: 0.3063 - accuracy: 0.8739 - val_loss: 0.3066 - val_accuracy: 0.8762\n",
      "Epoch 20/100\n",
      "1324/1328 [============================>.] - ETA: 0s - loss: 0.3048 - accuracy: 0.8741\n",
      "Epoch 20: val_loss did not improve from 0.30662\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.3048 - accuracy: 0.8741 - val_loss: 0.3146 - val_accuracy: 0.8685\n",
      "Epoch 21/100\n",
      "1324/1328 [============================>.] - ETA: 0s - loss: 0.3002 - accuracy: 0.8764\n",
      "Epoch 21: val_loss improved from 0.30662 to 0.30537, saving model to models/model.hdf5\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.3001 - accuracy: 0.8765 - val_loss: 0.3054 - val_accuracy: 0.8768\n",
      "Epoch 22/100\n",
      "1322/1328 [============================>.] - ETA: 0s - loss: 0.2990 - accuracy: 0.8777\n",
      "Epoch 22: val_loss improved from 0.30537 to 0.29778, saving model to models/model.hdf5\n",
      "1328/1328 [==============================] - 9s 6ms/step - loss: 0.2990 - accuracy: 0.8778 - val_loss: 0.2978 - val_accuracy: 0.8813\n",
      "Epoch 23/100\n",
      "1324/1328 [============================>.] - ETA: 0s - loss: 0.2946 - accuracy: 0.8796\n",
      "Epoch 23: val_loss improved from 0.29778 to 0.28799, saving model to models/model.hdf5\n",
      "1328/1328 [==============================] - 8s 6ms/step - loss: 0.2947 - accuracy: 0.8795 - val_loss: 0.2880 - val_accuracy: 0.8844\n",
      "Epoch 24/100\n",
      "1326/1328 [============================>.] - ETA: 0s - loss: 0.2985 - accuracy: 0.8772\n",
      "Epoch 24: val_loss did not improve from 0.28799\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.2986 - accuracy: 0.8771 - val_loss: 0.2992 - val_accuracy: 0.8781\n",
      "Epoch 25/100\n",
      "1327/1328 [============================>.] - ETA: 0s - loss: 0.2901 - accuracy: 0.8831\n",
      "Epoch 25: val_loss did not improve from 0.28799\n",
      "1328/1328 [==============================] - 8s 6ms/step - loss: 0.2901 - accuracy: 0.8831 - val_loss: 0.3023 - val_accuracy: 0.8761\n",
      "Epoch 26/100\n",
      "1322/1328 [============================>.] - ETA: 0s - loss: 0.2928 - accuracy: 0.8803\n",
      "Epoch 26: val_loss did not improve from 0.28799\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.2927 - accuracy: 0.8803 - val_loss: 0.2918 - val_accuracy: 0.8825\n",
      "Epoch 27/100\n",
      "1328/1328 [==============================] - ETA: 0s - loss: 0.2907 - accuracy: 0.8816\n",
      "Epoch 27: val_loss improved from 0.28799 to 0.28784, saving model to models/model.hdf5\n",
      "1328/1328 [==============================] - 10s 8ms/step - loss: 0.2907 - accuracy: 0.8816 - val_loss: 0.2878 - val_accuracy: 0.8816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100\n",
      "1320/1328 [============================>.] - ETA: 0s - loss: 0.2909 - accuracy: 0.8810\n",
      "Epoch 28: val_loss improved from 0.28784 to 0.28764, saving model to models/model.hdf5\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.2912 - accuracy: 0.8809 - val_loss: 0.2876 - val_accuracy: 0.8832\n",
      "Epoch 29/100\n",
      "1322/1328 [============================>.] - ETA: 0s - loss: 0.2906 - accuracy: 0.8816\n",
      "Epoch 29: val_loss did not improve from 0.28764\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.2905 - accuracy: 0.8816 - val_loss: 0.3010 - val_accuracy: 0.8752\n",
      "Epoch 30/100\n",
      "1322/1328 [============================>.] - ETA: 0s - loss: 0.2867 - accuracy: 0.8830\n",
      "Epoch 30: val_loss improved from 0.28764 to 0.28269, saving model to models/model.hdf5\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.2869 - accuracy: 0.8828 - val_loss: 0.2827 - val_accuracy: 0.8893\n",
      "Epoch 31/100\n",
      "1321/1328 [============================>.] - ETA: 0s - loss: 0.2841 - accuracy: 0.8854\n",
      "Epoch 31: val_loss did not improve from 0.28269\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.2841 - accuracy: 0.8854 - val_loss: 0.2936 - val_accuracy: 0.8822\n",
      "Epoch 32/100\n",
      "1324/1328 [============================>.] - ETA: 0s - loss: 0.2851 - accuracy: 0.8844\n",
      "Epoch 32: val_loss improved from 0.28269 to 0.27281, saving model to models/model.hdf5\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.2849 - accuracy: 0.8845 - val_loss: 0.2728 - val_accuracy: 0.8942\n",
      "Epoch 33/100\n",
      "1326/1328 [============================>.] - ETA: 0s - loss: 0.2817 - accuracy: 0.8869\n",
      "Epoch 33: val_loss did not improve from 0.27281\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.2817 - accuracy: 0.8870 - val_loss: 0.2764 - val_accuracy: 0.8908\n",
      "Epoch 34/100\n",
      "1323/1328 [============================>.] - ETA: 0s - loss: 0.2795 - accuracy: 0.8865\n",
      "Epoch 34: val_loss did not improve from 0.27281\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.2796 - accuracy: 0.8864 - val_loss: 0.2813 - val_accuracy: 0.8880\n",
      "Epoch 35/100\n",
      "1325/1328 [============================>.] - ETA: 0s - loss: 0.2818 - accuracy: 0.8862\n",
      "Epoch 35: val_loss did not improve from 0.27281\n",
      "1328/1328 [==============================] - 8s 6ms/step - loss: 0.2821 - accuracy: 0.8860 - val_loss: 0.2823 - val_accuracy: 0.8884\n",
      "Epoch 36/100\n",
      "1328/1328 [==============================] - ETA: 0s - loss: 0.2832 - accuracy: 0.8851\n",
      "Epoch 36: val_loss did not improve from 0.27281\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.2832 - accuracy: 0.8851 - val_loss: 0.2765 - val_accuracy: 0.8918\n",
      "Epoch 37/100\n",
      "1327/1328 [============================>.] - ETA: 0s - loss: 0.2780 - accuracy: 0.8882\n",
      "Epoch 37: val_loss did not improve from 0.27281\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.2781 - accuracy: 0.8882 - val_loss: 0.2747 - val_accuracy: 0.8925\n",
      "Epoch 38/100\n",
      "1323/1328 [============================>.] - ETA: 0s - loss: 0.2740 - accuracy: 0.8903\n",
      "Epoch 38: val_loss improved from 0.27281 to 0.27247, saving model to models/model.hdf5\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.2739 - accuracy: 0.8903 - val_loss: 0.2725 - val_accuracy: 0.8920\n",
      "Epoch 39/100\n",
      "1326/1328 [============================>.] - ETA: 0s - loss: 0.2772 - accuracy: 0.8882\n",
      "Epoch 39: val_loss did not improve from 0.27247\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.2773 - accuracy: 0.8882 - val_loss: 0.2892 - val_accuracy: 0.8807\n",
      "Epoch 40/100\n",
      "1325/1328 [============================>.] - ETA: 0s - loss: 0.2734 - accuracy: 0.8907\n",
      "Epoch 40: val_loss improved from 0.27247 to 0.26554, saving model to models/model.hdf5\n",
      "1328/1328 [==============================] - 8s 6ms/step - loss: 0.2734 - accuracy: 0.8907 - val_loss: 0.2655 - val_accuracy: 0.8985\n",
      "Epoch 41/100\n",
      "1327/1328 [============================>.] - ETA: 0s - loss: 0.2721 - accuracy: 0.8908\n",
      "Epoch 41: val_loss did not improve from 0.26554\n",
      "1328/1328 [==============================] - 9s 6ms/step - loss: 0.2721 - accuracy: 0.8908 - val_loss: 0.2916 - val_accuracy: 0.8813\n",
      "Epoch 42/100\n",
      "1319/1328 [============================>.] - ETA: 0s - loss: 0.2752 - accuracy: 0.8890\n",
      "Epoch 42: val_loss did not improve from 0.26554\n",
      "1328/1328 [==============================] - 8s 6ms/step - loss: 0.2755 - accuracy: 0.8888 - val_loss: 0.2692 - val_accuracy: 0.8983\n",
      "Epoch 43/100\n",
      "1321/1328 [============================>.] - ETA: 0s - loss: 0.2731 - accuracy: 0.8895\n",
      "Epoch 43: val_loss did not improve from 0.26554\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.2732 - accuracy: 0.8894 - val_loss: 0.2927 - val_accuracy: 0.8794\n",
      "Epoch 44/100\n",
      "1327/1328 [============================>.] - ETA: 0s - loss: 0.2715 - accuracy: 0.8908\n",
      "Epoch 44: val_loss did not improve from 0.26554\n",
      "1328/1328 [==============================] - 8s 6ms/step - loss: 0.2715 - accuracy: 0.8908 - val_loss: 0.2701 - val_accuracy: 0.8969\n",
      "Epoch 45/100\n",
      "1324/1328 [============================>.] - ETA: 0s - loss: 0.2709 - accuracy: 0.8916\n",
      "Epoch 45: val_loss did not improve from 0.26554\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.2709 - accuracy: 0.8916 - val_loss: 0.2701 - val_accuracy: 0.8978\n",
      "Epoch 46/100\n",
      "1324/1328 [============================>.] - ETA: 0s - loss: 0.2688 - accuracy: 0.8925\n",
      "Epoch 46: val_loss did not improve from 0.26554\n",
      "1328/1328 [==============================] - 8s 6ms/step - loss: 0.2688 - accuracy: 0.8925 - val_loss: 0.2930 - val_accuracy: 0.8830\n",
      "Epoch 47/100\n",
      "1322/1328 [============================>.] - ETA: 0s - loss: 0.2730 - accuracy: 0.8906\n",
      "Epoch 47: val_loss did not improve from 0.26554\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.2728 - accuracy: 0.8907 - val_loss: 0.2864 - val_accuracy: 0.8836\n",
      "Epoch 48/100\n",
      "1324/1328 [============================>.] - ETA: 0s - loss: 0.2686 - accuracy: 0.8934\n",
      "Epoch 48: val_loss did not improve from 0.26554\n",
      "1328/1328 [==============================] - 10s 8ms/step - loss: 0.2686 - accuracy: 0.8933 - val_loss: 0.2864 - val_accuracy: 0.8875\n",
      "Epoch 49/100\n",
      "1322/1328 [============================>.] - ETA: 0s - loss: 0.2678 - accuracy: 0.8934\n",
      "Epoch 49: val_loss did not improve from 0.26554\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.2678 - accuracy: 0.8934 - val_loss: 0.2829 - val_accuracy: 0.8861\n",
      "Epoch 50/100\n",
      "1319/1328 [============================>.] - ETA: 0s - loss: 0.2684 - accuracy: 0.8933\n",
      "Epoch 50: val_loss improved from 0.26554 to 0.26309, saving model to models/model.hdf5\n",
      "1328/1328 [==============================] - 9s 6ms/step - loss: 0.2682 - accuracy: 0.8934 - val_loss: 0.2631 - val_accuracy: 0.8980\n",
      "Epoch 51/100\n",
      "1321/1328 [============================>.] - ETA: 0s - loss: 0.2657 - accuracy: 0.8940\n",
      "Epoch 51: val_loss did not improve from 0.26309\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.2657 - accuracy: 0.8940 - val_loss: 0.3122 - val_accuracy: 0.8680\n",
      "Epoch 52/100\n",
      "1328/1328 [==============================] - ETA: 0s - loss: 0.2669 - accuracy: 0.8937\n",
      "Epoch 52: val_loss did not improve from 0.26309\n",
      "1328/1328 [==============================] - 8s 6ms/step - loss: 0.2669 - accuracy: 0.8937 - val_loss: 0.2642 - val_accuracy: 0.9003\n",
      "Epoch 53/100\n",
      "1319/1328 [============================>.] - ETA: 0s - loss: 0.2656 - accuracy: 0.8945\n",
      "Epoch 53: val_loss did not improve from 0.26309\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.2653 - accuracy: 0.8947 - val_loss: 0.2708 - val_accuracy: 0.8939\n",
      "Epoch 54/100\n",
      "1320/1328 [============================>.] - ETA: 0s - loss: 0.2696 - accuracy: 0.8916\n",
      "Epoch 54: val_loss did not improve from 0.26309\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.2698 - accuracy: 0.8915 - val_loss: 0.2903 - val_accuracy: 0.8835\n",
      "Epoch 55/100\n",
      "1322/1328 [============================>.] - ETA: 0s - loss: 0.2627 - accuracy: 0.8952\n",
      "Epoch 55: val_loss did not improve from 0.26309\n",
      "1328/1328 [==============================] - 9s 6ms/step - loss: 0.2630 - accuracy: 0.8951 - val_loss: 0.2734 - val_accuracy: 0.8925\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1328 [============================>.] - ETA: 0s - loss: 0.2633 - accuracy: 0.8959\n",
      "Epoch 56: val_loss improved from 0.26309 to 0.26240, saving model to models/model.hdf5\n",
      "1328/1328 [==============================] - 8s 6ms/step - loss: 0.2632 - accuracy: 0.8959 - val_loss: 0.2624 - val_accuracy: 0.8998\n",
      "Epoch 57/100\n",
      "1326/1328 [============================>.] - ETA: 0s - loss: 0.2656 - accuracy: 0.8933\n",
      "Epoch 57: val_loss did not improve from 0.26240\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.2656 - accuracy: 0.8933 - val_loss: 0.2711 - val_accuracy: 0.8974\n",
      "Epoch 58/100\n",
      "1321/1328 [============================>.] - ETA: 0s - loss: 0.2633 - accuracy: 0.8944\n",
      "Epoch 58: val_loss did not improve from 0.26240\n",
      "1328/1328 [==============================] - 8s 6ms/step - loss: 0.2634 - accuracy: 0.8944 - val_loss: 0.3078 - val_accuracy: 0.8788\n",
      "Epoch 59/100\n",
      "1328/1328 [==============================] - ETA: 0s - loss: 0.2663 - accuracy: 0.8936\n",
      "Epoch 59: val_loss did not improve from 0.26240\n",
      "1328/1328 [==============================] - 9s 6ms/step - loss: 0.2663 - accuracy: 0.8936 - val_loss: 0.2627 - val_accuracy: 0.9019\n",
      "Epoch 60/100\n",
      "1325/1328 [============================>.] - ETA: 0s - loss: 0.2617 - accuracy: 0.8959\n",
      "Epoch 60: val_loss improved from 0.26240 to 0.26087, saving model to models/model.hdf5\n",
      "1328/1328 [==============================] - 8s 6ms/step - loss: 0.2617 - accuracy: 0.8958 - val_loss: 0.2609 - val_accuracy: 0.9014\n",
      "Epoch 61/100\n",
      "1326/1328 [============================>.] - ETA: 0s - loss: 0.2646 - accuracy: 0.8947\n",
      "Epoch 61: val_loss did not improve from 0.26087\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.2646 - accuracy: 0.8948 - val_loss: 0.2766 - val_accuracy: 0.8919\n",
      "Epoch 62/100\n",
      "1325/1328 [============================>.] - ETA: 0s - loss: 0.2622 - accuracy: 0.8966\n",
      "Epoch 62: val_loss did not improve from 0.26087\n",
      "1328/1328 [==============================] - 9s 6ms/step - loss: 0.2622 - accuracy: 0.8966 - val_loss: 0.2822 - val_accuracy: 0.8897\n",
      "Epoch 63/100\n",
      "1325/1328 [============================>.] - ETA: 0s - loss: 0.2609 - accuracy: 0.8960\n",
      "Epoch 63: val_loss did not improve from 0.26087\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.2609 - accuracy: 0.8960 - val_loss: 0.2645 - val_accuracy: 0.9000\n",
      "Epoch 64/100\n",
      "1319/1328 [============================>.] - ETA: 0s - loss: 0.2625 - accuracy: 0.8953\n",
      "Epoch 64: val_loss did not improve from 0.26087\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.2628 - accuracy: 0.8952 - val_loss: 0.2874 - val_accuracy: 0.8865\n",
      "Epoch 65/100\n",
      "1328/1328 [==============================] - ETA: 0s - loss: 0.2593 - accuracy: 0.8971\n",
      "Epoch 65: val_loss did not improve from 0.26087\n",
      "1328/1328 [==============================] - 8s 6ms/step - loss: 0.2593 - accuracy: 0.8971 - val_loss: 0.3083 - val_accuracy: 0.8764\n",
      "Epoch 66/100\n",
      "1319/1328 [============================>.] - ETA: 0s - loss: 0.2588 - accuracy: 0.8977\n",
      "Epoch 66: val_loss did not improve from 0.26087\n",
      "1328/1328 [==============================] - 8s 6ms/step - loss: 0.2591 - accuracy: 0.8976 - val_loss: 0.2685 - val_accuracy: 0.8982\n",
      "Epoch 67/100\n",
      "1323/1328 [============================>.] - ETA: 0s - loss: 0.2594 - accuracy: 0.8970\n",
      "Epoch 67: val_loss did not improve from 0.26087\n",
      "1328/1328 [==============================] - 8s 6ms/step - loss: 0.2595 - accuracy: 0.8969 - val_loss: 0.2973 - val_accuracy: 0.8806\n",
      "Epoch 68/100\n",
      "1322/1328 [============================>.] - ETA: 0s - loss: 0.2614 - accuracy: 0.8963\n",
      "Epoch 68: val_loss did not improve from 0.26087\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.2613 - accuracy: 0.8963 - val_loss: 0.2721 - val_accuracy: 0.8935\n",
      "Epoch 69/100\n",
      "1324/1328 [============================>.] - ETA: 0s - loss: 0.2577 - accuracy: 0.8984\n",
      "Epoch 69: val_loss improved from 0.26087 to 0.25957, saving model to models/model.hdf5\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.2576 - accuracy: 0.8985 - val_loss: 0.2596 - val_accuracy: 0.9033\n",
      "Epoch 70/100\n",
      "1325/1328 [============================>.] - ETA: 0s - loss: 0.2576 - accuracy: 0.8979\n",
      "Epoch 70: val_loss did not improve from 0.25957\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.2575 - accuracy: 0.8979 - val_loss: 0.2610 - val_accuracy: 0.9005\n",
      "Epoch 71/100\n",
      "1323/1328 [============================>.] - ETA: 0s - loss: 0.2570 - accuracy: 0.8984\n",
      "Epoch 71: val_loss did not improve from 0.25957\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.2572 - accuracy: 0.8984 - val_loss: 0.2790 - val_accuracy: 0.8897\n",
      "Epoch 72/100\n",
      "1323/1328 [============================>.] - ETA: 0s - loss: 0.2580 - accuracy: 0.8979\n",
      "Epoch 72: val_loss did not improve from 0.25957\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.2578 - accuracy: 0.8980 - val_loss: 0.2610 - val_accuracy: 0.9015\n",
      "Epoch 73/100\n",
      "1325/1328 [============================>.] - ETA: 0s - loss: 0.2592 - accuracy: 0.8978\n",
      "Epoch 73: val_loss did not improve from 0.25957\n",
      "1328/1328 [==============================] - 8s 6ms/step - loss: 0.2592 - accuracy: 0.8978 - val_loss: 0.2766 - val_accuracy: 0.8886\n",
      "Epoch 74/100\n",
      "1326/1328 [============================>.] - ETA: 0s - loss: 0.2564 - accuracy: 0.8993\n",
      "Epoch 74: val_loss did not improve from 0.25957\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.2564 - accuracy: 0.8993 - val_loss: 0.2701 - val_accuracy: 0.8980\n",
      "Epoch 75/100\n",
      "1320/1328 [============================>.] - ETA: 0s - loss: 0.2567 - accuracy: 0.8981\n",
      "Epoch 75: val_loss did not improve from 0.25957\n",
      "1328/1328 [==============================] - 9s 6ms/step - loss: 0.2566 - accuracy: 0.8981 - val_loss: 0.2619 - val_accuracy: 0.9016\n",
      "Epoch 76/100\n",
      "1323/1328 [============================>.] - ETA: 0s - loss: 0.2564 - accuracy: 0.8980\n",
      "Epoch 76: val_loss improved from 0.25957 to 0.25753, saving model to models/model.hdf5\n",
      "1328/1328 [==============================] - 8s 6ms/step - loss: 0.2563 - accuracy: 0.8980 - val_loss: 0.2575 - val_accuracy: 0.9042\n",
      "Epoch 77/100\n",
      "1323/1328 [============================>.] - ETA: 0s - loss: 0.2567 - accuracy: 0.8984\n",
      "Epoch 77: val_loss did not improve from 0.25753\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.2566 - accuracy: 0.8985 - val_loss: 0.3078 - val_accuracy: 0.8723\n",
      "Epoch 78/100\n",
      "1324/1328 [============================>.] - ETA: 0s - loss: 0.2530 - accuracy: 0.8995\n",
      "Epoch 78: val_loss did not improve from 0.25753\n",
      "1328/1328 [==============================] - 8s 6ms/step - loss: 0.2531 - accuracy: 0.8995 - val_loss: 0.2608 - val_accuracy: 0.8999\n",
      "Epoch 79/100\n",
      "1326/1328 [============================>.] - ETA: 0s - loss: 0.2528 - accuracy: 0.8995\n",
      "Epoch 79: val_loss did not improve from 0.25753\n",
      "1328/1328 [==============================] - 9s 6ms/step - loss: 0.2529 - accuracy: 0.8995 - val_loss: 0.3329 - val_accuracy: 0.8592\n",
      "Epoch 80/100\n",
      "1322/1328 [============================>.] - ETA: 0s - loss: 0.2560 - accuracy: 0.8978\n",
      "Epoch 80: val_loss did not improve from 0.25753\n",
      "1328/1328 [==============================] - 9s 6ms/step - loss: 0.2559 - accuracy: 0.8977 - val_loss: 0.2695 - val_accuracy: 0.8986\n",
      "Epoch 81/100\n",
      "1321/1328 [============================>.] - ETA: 0s - loss: 0.2522 - accuracy: 0.8998\n",
      "Epoch 81: val_loss did not improve from 0.25753\n",
      "1328/1328 [==============================] - 8s 6ms/step - loss: 0.2521 - accuracy: 0.8999 - val_loss: 0.2761 - val_accuracy: 0.8914\n",
      "Epoch 82/100\n",
      "1321/1328 [============================>.] - ETA: 0s - loss: 0.2543 - accuracy: 0.8994\n",
      "Epoch 82: val_loss did not improve from 0.25753\n",
      "1328/1328 [==============================] - 9s 6ms/step - loss: 0.2542 - accuracy: 0.8994 - val_loss: 0.2617 - val_accuracy: 0.9016\n",
      "Epoch 83/100\n",
      "1323/1328 [============================>.] - ETA: 0s - loss: 0.2552 - accuracy: 0.8989\n",
      "Epoch 83: val_loss did not improve from 0.25753\n",
      "1328/1328 [==============================] - 8s 6ms/step - loss: 0.2552 - accuracy: 0.8988 - val_loss: 0.3182 - val_accuracy: 0.8694\n",
      "Epoch 84/100\n",
      "1324/1328 [============================>.] - ETA: 0s - loss: 0.2520 - accuracy: 0.9005\n",
      "Epoch 84: val_loss did not improve from 0.25753\n",
      "1328/1328 [==============================] - 8s 6ms/step - loss: 0.2520 - accuracy: 0.9005 - val_loss: 0.2692 - val_accuracy: 0.9000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100\n",
      "1321/1328 [============================>.] - ETA: 0s - loss: 0.2533 - accuracy: 0.8992\n",
      "Epoch 85: val_loss did not improve from 0.25753\n",
      "1328/1328 [==============================] - 9s 6ms/step - loss: 0.2529 - accuracy: 0.8994 - val_loss: 0.2617 - val_accuracy: 0.9039\n",
      "Epoch 86/100\n",
      "1327/1328 [============================>.] - ETA: 0s - loss: 0.2521 - accuracy: 0.9001\n",
      "Epoch 86: val_loss did not improve from 0.25753\n",
      "1328/1328 [==============================] - 8s 6ms/step - loss: 0.2521 - accuracy: 0.9001 - val_loss: 0.2655 - val_accuracy: 0.9025\n",
      "Epoch 87/100\n",
      "1326/1328 [============================>.] - ETA: 0s - loss: 0.2492 - accuracy: 0.9021\n",
      "Epoch 87: val_loss did not improve from 0.25753\n",
      "1328/1328 [==============================] - 8s 6ms/step - loss: 0.2492 - accuracy: 0.9021 - val_loss: 0.2825 - val_accuracy: 0.8874\n",
      "Epoch 88/100\n",
      "1319/1328 [============================>.] - ETA: 0s - loss: 0.2513 - accuracy: 0.9006\n",
      "Epoch 88: val_loss did not improve from 0.25753\n",
      "1328/1328 [==============================] - 8s 6ms/step - loss: 0.2514 - accuracy: 0.9006 - val_loss: 0.2658 - val_accuracy: 0.9005\n",
      "Epoch 89/100\n",
      "1328/1328 [==============================] - ETA: 0s - loss: 0.2496 - accuracy: 0.9014\n",
      "Epoch 89: val_loss did not improve from 0.25753\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.2496 - accuracy: 0.9014 - val_loss: 0.2880 - val_accuracy: 0.8920\n",
      "Epoch 90/100\n",
      "1321/1328 [============================>.] - ETA: 0s - loss: 0.2523 - accuracy: 0.8993\n",
      "Epoch 90: val_loss did not improve from 0.25753\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.2524 - accuracy: 0.8992 - val_loss: 0.2652 - val_accuracy: 0.8993\n",
      "Epoch 91/100\n",
      "1322/1328 [============================>.] - ETA: 0s - loss: 0.2511 - accuracy: 0.9005\n",
      "Epoch 91: val_loss did not improve from 0.25753\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.2512 - accuracy: 0.9003 - val_loss: 0.3358 - val_accuracy: 0.8688\n",
      "Epoch 92/100\n",
      "1327/1328 [============================>.] - ETA: 0s - loss: 0.2508 - accuracy: 0.9008\n",
      "Epoch 92: val_loss did not improve from 0.25753\n",
      "1328/1328 [==============================] - 9s 6ms/step - loss: 0.2508 - accuracy: 0.9008 - val_loss: 0.2642 - val_accuracy: 0.9007\n",
      "Epoch 93/100\n",
      "1327/1328 [============================>.] - ETA: 0s - loss: 0.2496 - accuracy: 0.9019\n",
      "Epoch 93: val_loss did not improve from 0.25753\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.2495 - accuracy: 0.9019 - val_loss: 0.2609 - val_accuracy: 0.9034\n",
      "Epoch 94/100\n",
      "1321/1328 [============================>.] - ETA: 0s - loss: 0.2477 - accuracy: 0.9023\n",
      "Epoch 94: val_loss did not improve from 0.25753\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.2475 - accuracy: 0.9024 - val_loss: 0.2761 - val_accuracy: 0.8930\n",
      "Epoch 95/100\n",
      "1325/1328 [============================>.] - ETA: 0s - loss: 0.2526 - accuracy: 0.8998\n",
      "Epoch 95: val_loss did not improve from 0.25753\n",
      "1328/1328 [==============================] - 8s 6ms/step - loss: 0.2525 - accuracy: 0.8998 - val_loss: 0.2615 - val_accuracy: 0.9051\n",
      "Epoch 96/100\n",
      "1323/1328 [============================>.] - ETA: 0s - loss: 0.2458 - accuracy: 0.9031\n",
      "Epoch 96: val_loss did not improve from 0.25753\n",
      "1328/1328 [==============================] - 8s 6ms/step - loss: 0.2461 - accuracy: 0.9030 - val_loss: 0.2724 - val_accuracy: 0.8949\n",
      "Epoch 97/100\n",
      "1320/1328 [============================>.] - ETA: 0s - loss: 0.2482 - accuracy: 0.9022\n",
      "Epoch 97: val_loss did not improve from 0.25753\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.2482 - accuracy: 0.9023 - val_loss: 0.2764 - val_accuracy: 0.8983\n",
      "Epoch 98/100\n",
      "1319/1328 [============================>.] - ETA: 0s - loss: 0.2482 - accuracy: 0.9005\n",
      "Epoch 98: val_loss did not improve from 0.25753\n",
      "1328/1328 [==============================] - 8s 6ms/step - loss: 0.2483 - accuracy: 0.9005 - val_loss: 0.2628 - val_accuracy: 0.9040\n",
      "Epoch 99/100\n",
      "1323/1328 [============================>.] - ETA: 0s - loss: 0.2481 - accuracy: 0.9018\n",
      "Epoch 99: val_loss did not improve from 0.25753\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.2481 - accuracy: 0.9019 - val_loss: 0.2760 - val_accuracy: 0.8977\n",
      "Epoch 100/100\n",
      "1327/1328 [============================>.] - ETA: 0s - loss: 0.2498 - accuracy: 0.9009\n",
      "Epoch 100: val_loss did not improve from 0.25753\n",
      "1328/1328 [==============================] - 9s 7ms/step - loss: 0.2498 - accuracy: 0.9009 - val_loss: 0.2817 - val_accuracy: 0.8931\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.99      0.90     25893\n",
      "         1.0       0.99      0.80      0.88     26128\n",
      "\n",
      "    accuracy                           0.89     52021\n",
      "   macro avg       0.91      0.89      0.89     52021\n",
      "weighted avg       0.91      0.89      0.89     52021\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history = model_training_cnn(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49a57923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
